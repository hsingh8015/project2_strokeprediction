


import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV





stroke_df = pd.read_csv("healthcare-dataset-stroke-data.csv")
stroke_df


# make a copy so we keep the original data untouched
stroke_copy = stroke_df.copy()


#with na's dropped we hardly lose data so we decided to just drop NA's
stroke_copy.dropna()


#The id column is irrelevant so just decided to drop it.
stroke_copy = stroke_copy.drop(columns=['id'])


stroke_copy.info()





ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')


categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']


numerical_columns = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']


stroke_categorical = stroke_copy[categorical_columns]
stroke_numerical = stroke_copy[numerical_columns]


ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')
stroke_categorical = pd.DataFrame(data=ohe.fit_transform(stroke_categorical), 
                                           columns=ohe.get_feature_names_out(categorical_columns))


stroke_encoded = pd.concat([stroke_numerical.reset_index(drop=True), stroke_categorical.reset_index(drop=True)], axis=1)
stroke_encoded.head()





X = stroke_encoded.drop(columns = 'stroke')
y = stroke_encoded['stroke']

X_train, X_test, y_train, y_test = train_test_split(X, y)


X_train.isna().sum()/len(stroke_encoded)








clf = RandomForestClassifier(random_state=42, n_estimators=500).fit(X_train, y_train)

# Evaluate the model
print(f'Training Score: {clf.score(X_train, y_train)}')
print(f'Testing Score: {clf.score(X_test, y_test)}')


feature_importances = clf.feature_importances_


importances_sorted = sorted(zip(feature_importances, X.columns), reverse=True)
importances_sorted[:10]


# Plot the feature importances
features = sorted(zip(X.columns, feature_importances), key = lambda x: x[1])
cols = [f[0] for f in features]
width = [f[1] for f in features]

fig, ax = plt.subplots()

fig.set_size_inches(8,6)
plt.margins(y=0.001)

ax.barh(y=cols, width=width)

plt.show()





#initialize the model
random_tuned_model = RandomForestClassifier()
grid_tuned_model = RandomForestClassifier()
best_model = RandomForestClassifier()


#set params
param_distributions = {
    'n_estimators': [100, 200, 300, 500],
    'max_features': [0.5, 'sqrt', 'log2', None],  
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Set up the RandomizedSearchCV
rf_random = RandomizedSearchCV(estimator=random_tuned_model, param_distributions=param_distributions, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)

# Fit the model
rf_random.fit(X_train, y_train)

best_params = rf_random.best_params_
print("Best parameters found: ", best_params)



best_params = rf_random.best_params_
print("Best parameters found: ", best_params)


random_rf_model = rf_random.best_estimator_

# Make predictions using the best model
best_rf_predictions = random_rf_model.predict(X_test)

# Evaluate the accuracy of the best model
random_accuracy = accuracy_score(y_test, best_rf_predictions)
print("Random accuracy: ", random_accuracy)


param_grid = {
    'max_features': [best_params['max_features']],
    'max_depth': [max(1, best_params['max_depth'] - 10), best_params['max_depth'], best_params['max_depth'] + 10],
    'min_samples_leaf': [
        max(1, best_params['min_samples_leaf'] - 1), 
        best_params['min_samples_leaf'], 
        best_params['min_samples_leaf'] + 1
    ]
}

grid_search = GridSearchCV(estimator=grid_tuned_model, param_grid=param_grid, cv=3)
grid_search.fit(X_train, y_train)

print("Best parameters after grid search: ", grid_search.best_params_)


final_model = RandomForestClassifier(n_estimators=300,
                         min_samples_split=5,
                         min_samples_leaf=3,
                         max_depth=30,
                         max_features=0.5,
                         bootstrap=True,
                         )
final_model.fit(X_train, y_train)


print(f'Training Score: {final_model.score(X_train, y_train)}')
print(f'Testing Score: {final_model.score(X_test, y_test)}')



