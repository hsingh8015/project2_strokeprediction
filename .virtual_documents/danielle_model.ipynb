


import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier
!pip install imbalanced-learn





stroke_df = pd.read_csv("healthcare-dataset-stroke-data.csv")
stroke_df


# make a copy so we keep the original data untouched
stroke_copy = stroke_df.copy()


#with na's dropped we hardly lose data so we decided to just drop NA's
stroke_copy.dropna(inplace=True)


#The id column is irrelevant so just decided to drop it.
stroke_copy = stroke_copy.drop(columns=['id'])


stroke_copy.info()





ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')


categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']


numerical_columns = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']


stroke_categorical = stroke_copy[categorical_columns]
stroke_numerical = stroke_copy[numerical_columns]


ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')
stroke_categorical = pd.DataFrame(data=ohe.fit_transform(stroke_categorical), 
                                           columns=ohe.get_feature_names_out(categorical_columns))


stroke_encoded = pd.concat([stroke_numerical.reset_index(drop=True), stroke_categorical.reset_index(drop=True)], axis=1)
stroke_encoded.head()





X = stroke_encoded.drop(columns = 'stroke')
y = stroke_encoded['stroke']

X_train, X_test, y_train, y_test = train_test_split(X, y)


X_train.isna().sum()/len(stroke_encoded)





# Scale
# Create a StandardScater model and fit it to the training data
X_scaler = StandardScaler()
X_scaler.fit(X_train)


# Transform the training and testing data by using the X_scaler model
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)


#Apply SMOTE to the training data:
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)

# Check the new class distribution:
print(pd.Series(y_resampled).value_counts())


# Create a `LogisticRegression` function and assign it 
# to a variable named `logistic_regression_model`.
logistic_regression_model = LogisticRegression()

# Fit the model
logistic_regression_model.fit(X_train_scaled, y_train)


# Score the model
print(f"Training Data Score: {logistic_regression_model.score(X_train_scaled, y_train)}")
print(f"Testing Data Score: {logistic_regression_model.score(X_test_scaled, y_test)}")


# Create a SMOTE `LogisticRegression` function and assign it 
# to a variable named `logistic_regression_model`.
logistic_regression_model_smote = LogisticRegression()

# Fit the model
logistic_regression_model_smote.fit(X_resampled, y_resampled)


# Score the SMOTE LR model
print(f"SMOTE Training Data Score: {logistic_regression_model_smote.score(X_resampled, y_resampled)}")
print(f"SMOTE Testing Data Score: {logistic_regression_model_smote.score(X_test_scaled, y_test)}")


# SMOTE Predict
y_pred_resampled = logistic_regression_model_smote.predict(X_test_scaled)


# SMOTE Confusion Matrix
cm = confusion_matrix(y_test, y_pred_resampled)
print(cm)


# Scaled Predict
y_pred = logistic_regression_model.predict(X_test_scaled)


# Scaled Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)





# Create a SMOTE `LogisticRegression` function and assign it 
# to a variable named `logistic_regression_model`.
random_forest_model_smote = RandomForestClassifier()

# Fit the model
random_forest_model_smote.fit(X_resampled, y_resampled)


# Evaluate the SMOTE Random Forest model
print(f'Training Score: {random_forest_model_smote.score(X_resampled, y_resampled)}')
print(f'Testing Score: {random_forest_model_smote.score(X_test_scaled, y_test)}')


# SMOTE Predict
y_pred_resampled = random_forest_model_smote.predict(X_test_scaled)


# SMOTE Confusion Matrix
cm = confusion_matrix(y_test, y_pred_resampled)
print(cm)





# Train the Gradient Boosting classifier
clf = GradientBoostingClassifier(random_state=1).fit(X_resampled, y_resampled)
# Evaluate the model
print(f'Training Score: {clf.score(X_resampled, y_resampled)}')
print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')


# SMOTE Predict Gradient Boost
y_pred_clf = clf.predict(X_test_scaled)


# SMOTE Confusion Matrix Gradient Boost
cm = confusion_matrix(y_test, y_pred_clf)
print(cm)


# GridSearch


#Set up the parameter grid:

param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5]
}


# Create the GridSearchCV object

grid_clf = GridSearchCV(model, param_grid, verbose=3, cv=5)


# Fit the model

grid_clf.fit(X_resampled, y_resampled)


# Check the best parameters

print("Best parameters found: ", grid_clf.best_params_)








# Create a `SVC` function and assign it to a variable named `model`.
model = SVC(kernel='linear')
model.fit(X_train_scaled, y_train)

# Score the model
print('Train Accuracy: %.3f' % model.score(X_train_scaled, y_train))
print('Test Accuracy: %.3f' % model.score(X_test_scaled, y_test))





from sklearn import tree
model = tree.DecisionTreeClassifier(max_depth=5)
model = model.fit(X_train_scaled, y_train)
predictions = model.predict(X_test_scaled)
acc_score = accuracy_score(y_test, predictions)
print(f"Accuracy Score : {acc_score}")


# import pydotplus
# from IPython.display import Image

# # Create DOT data
# dot_data = tree.export_graphviz(
#     model, out_file=None, feature_names=X.columns, class_names=["0", "1"], filled=True
# )
# # Draw graph
# graph = pydotplus.graph_from_dot_data(dot_data)
# # Show graph
# Image(graph.create_png())



