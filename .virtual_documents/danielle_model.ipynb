


import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV





stroke_df = pd.read_csv("healthcare-dataset-stroke-data.csv")
stroke_df


# make a copy so we keep the original data untouched
stroke_copy = stroke_df.copy()


#with na's dropped we hardly lose data so we decided to just drop NA's
stroke_copy.dropna(inplace=True)


#The id column is irrelevant so just decided to drop it.
stroke_copy = stroke_copy.drop(columns=['id'])


stroke_copy.info()





ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')


categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']


numerical_columns = ['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']


stroke_categorical = stroke_copy[categorical_columns]
stroke_numerical = stroke_copy[numerical_columns]


ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype='int')
stroke_categorical = pd.DataFrame(data=ohe.fit_transform(stroke_categorical), 
                                           columns=ohe.get_feature_names_out(categorical_columns))


stroke_encoded = pd.concat([stroke_numerical.reset_index(drop=True), stroke_categorical.reset_index(drop=True)], axis=1)
stroke_encoded.head()





X = stroke_encoded.drop(columns = 'stroke')
y = stroke_encoded['stroke']

X_train, X_test, y_train, y_test = train_test_split(X, y)


X_train.isna().sum()/len(stroke_encoded)





# Scale
# Create a StandardScater model and fit it to the training data
X_scaler = StandardScaler()
X_scaler.fit(X_train)


# Transform the training and testing data by using the X_scaler model
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)


# Create a `LogisticRegression` function and assign it 
# to a variable named `logistic_regression_model`.
logistic_regression_model = LogisticRegression()

# Fit the model
logistic_regression_model.fit(X_train_scaled, y_train)


# Score the model
print(f"Training Data Score: {logistic_regression_model.score(X_train_scaled, y_train)}")
print(f"Testing Data Score: {logistic_regression_model.score(X_test_scaled, y_test)}")





# Create a `SVC` function and assign it to a variable named `model`.
model = SVC(kernel='linear')
model.fit(X_train_scaled, y_train)

# Score the model
print('Train Accuracy: %.3f' % model.score(X_train_scaled, y_train))
print('Test Accuracy: %.3f' % model.score(X_test_scaled, y_test))





from sklearn import tree
model = tree.DecisionTreeClassifier(max_depth=5)
model = model.fit(X_train_scaled, y_train)
predictions = model.predict(X_test_scaled)
acc_score = accuracy_score(y_test, predictions)
print(f"Accuracy Score : {acc_score}")


import pydotplus
from IPython.display import Image

# Create DOT data
dot_data = tree.export_graphviz(
    model, out_file=None, feature_names=X.columns, class_names=["0", "1"], filled=True
)
# Draw graph
graph = pydotplus.graph_from_dot_data(dot_data)
# Show graph
Image(graph.create_png())



